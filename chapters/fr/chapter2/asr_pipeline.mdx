# Reconnaissance automatique de la parole avec pipeline

La reconnaissance automatique de la parole (ASR pour *Automatic Speech Recognition*) est une t√¢che qui implique la transcription de l'enregistrement vocal en texte.
Cette t√¢che a de nombreuses applications pratiques, de la cr√©ation de sous-titres cod√©s pour les vid√©os √† l'activation des commandes vocales pour les assistants virtuels comme Siri et Alexa.

Dans cette section, nous utiliserons le pipeline `automatic-speech-recognition` pour transcrire un enregistrement audio d'une personne posant une question sur le paiement d'une facture en utilisant le m√™me jeu de donn√©es MINDS-14 qu'auparavant.

Pour commencer, chargez le jeu de donn√©es et sur√©chantillonnez-le √† 16 kHz comme d√©crit dans [Classification audio avec un pipeline](audio_classification_pipeline), si vous ne l'avez pas encore fait.

Pour transcrire un enregistrement audio, nous pouvons utiliser le pipeline de `automatic-speech-recognition` de ü§ó *Transformers*. Instancions le pipeline :

```py
from transformers import pipeline

asr = pipeline("automatic-speech-recognition")
```

Ensuite, nous allons prendre un exemple du jeu de donn√©es et transmettre ses donn√©es brutes au pipeline :

```py
example = minds[0]
asr(example["audio"]["array"])
```

**Sortie :**

```out
{"text": "I WOULD LIKE TO PAY MY ELECTRICITY BILL USING MY COD CAN YOU PLEASE ASSIST"}
# "Je voudrais payer ma facture d'√©lectricit√© avec ma morue, pouvez-vous m'aider"
```

Comparons cette sortie √† ce qu'est la transcription r√©elle pour cet exemple :

```py
example["english_transcription"]
``` 
**Sortie :**
```out
"I would like to pay my electricity bill using my card can you please assist"
# "Je voudrais payer ma facture d'√©lectricit√© avec ma carte, pouvez-vous m'aider"
``` 

Le mod√®le semble avoir fait un assez bon travail pour transcrire l'audio ! Il n'a eu qu'un mot erron√© (*card*) par rapport √† la transcription originale, ce qui est plut√¥t bon √©tant donn√© que le locuteur a un accent australien, o√π la lettre ¬´ r ¬ª est souvent silencieuse. Cela dit, je ne recommanderais pas d'essayer de payer votre prochaine facture d'√©lectricit√© avec un poisson !

Par d√©faut, ce pipeline utilise un mod√®le entra√Æn√© pour la reconnaissance automatique de la parole pour la langue anglaise, ce qui est tr√®s bien dans cet exemple. Si vous souhaitez essayer de transcrire d'autres sous-ensembles de MINDS-14 dans une langue diff√©rente, vous pouvez trouver un mod√®le ASR pr√©-entra√Æn√© sur le [ü§ó *Hub*](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&language=fr&sort=downloads).
Vous pouvez d'abord filtrer la liste des mod√®les par t√¢che, puis par langue. Une fois que vous avez trouv√© le mod√®le que vous aimez, passez son nom comme argument `model` au pipeline.

Essayons cela pour l‚Äô√©chantillon allemand de MINDS-14. Chargez le sous-ensemble `de-DE` :

```py
from datasets import load_dataset
from datasets import Audio

minds = load_dataset("PolyAI/minds14", name="de-DE", split="train")
minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
```

Obtenez un exemple et voyez ce que la transcription est cens√©e √™tre:

```py
example = minds[0]
example["transcription"]
```

**Sortie :**

```out
"ich m√∂chte gerne Geld auf mein Konto einzahlen"
```

Trouvez un mod√®le ASR pr√©-entra√Æn√© pour la langue allemande sur le ü§ó *Hub*, instanciez un pipeline et transcrivez l'exemple :

```py
from transformers import pipeline

asr = pipeline("automatic-speech-recognition", model="maxidl/wav2vec2-large-xlsr-german")
asr(example["audio"]["array"])
```

**Sortie :**

```out
{"text": "ich m√∂chte gerne geld auf mein konto einzallen"}
```

Identique !

Lorsque vous travaillez √† r√©soudre votre propre t√¢che, commencer par un pipeline simple comme ceux que nous avons montr√©s dans cette unit√© est un outil pr√©cieux qui offre plusieurs avantages :
- Il peut exister un mod√®le pr√©-entra√Æn√© qui r√©sout d√©j√† tr√®s bien votre t√¢che, vous faisant gagner beaucoup de temps
- `pipeline()` s'occupe de tout le pr√©/post-traitement pour vous, vous n'avez donc pas √† vous soucier d'obtenir les donn√©es dans le bon format pour un mod√®le
- Si le r√©sultat n'est pas id√©al, cela vous donne quand m√™me une base de r√©f√©rence rapide pour les ajustements futurs
- une fois que vous avez affin√© un mod√®le sur vos donn√©es personnalis√©es et que vous l'avez partag√© sur le *Hub*, toute la communaut√© pourra l'utiliser rapidement et sans effort via la m√©thode 'pipeline()' rendant l'IA plus accessible.
