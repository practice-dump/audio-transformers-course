# Lectures et ressources compl√©mentaires

Cette unit√© est une introduction pratique √† la reconnaissance automatique de la parole, l'une des t√¢ches les plus populaires dans le domaine audio.
Vous voulez en savoir plus ? Vous trouverez ici des ressources suppl√©mentaires (en anglais) qui vous aideront √† approfondir votre compr√©hension du sujet et √† am√©liorer votre exp√©rience d'apprentissage.

* [Whisper Talk](https://www.youtube.com/live/fZMiD8sDzzg?feature=share) par Jong Wook Kim : une pr√©sentation du mod√®le Whisper, expliquant la motivation, l'architecture, l'entra√Ænement et les r√©sultats, par l'auteur du mod√®le.
* [End-to-End Speech Benchmark (ESB)](https://arxiv.org/abs/2210.13352) : un papier qui plaide en faveur de l'utilisation du WER orthographique plut√¥t que du WER normalis√© pour l'√©valuation des syst√®mes de reconnaissance automatique de la parole et qui pr√©sente un benchmark correspondant.
* [Fine-Tuning Whisper for Multilingual ASR](https://huggingface.co/blog/fine-tune-whisper) : un article de blog qui explique le fonctionnement du mod√®le Whisper de mani√®re plus d√©taill√©e, ainsi que les √©tapes de pr√©- et post-traitement impliqu√©es dans l'extracteur de caract√©ristiques et le *tokenizer*.
* [Fine-tuning MMS Adapter Models for Multi-Lingual ASR](https://huggingface.co/blog/mms_adapters) : un guide complet pour *finetuner* les nouveaux mod√®les de reconnaissance vocale [MMS](https://ai.facebook.com/blog/multilingual-model-speech-recognition/) de Meta, en gelant les poids du mod√®le de base et en ne finetunant qu'un petit nombre de couches.
* Boosting Wav2Vec2 with n-grams in ü§ó Transformers](https://huggingface.co/blog/wav2vec2-with-ngram) : un article de blog pour combiner les mod√®les CTC avec des mod√®les de langage externes pour combattre les erreurs d'orthographe et de ponctuation.
